# Disclaimer: This function was generated by AI. Please review before using.
# Agent Name: data_cleaning_agent
# Time Created: 2025-03-28 10:06:37

def data_cleaner(data_raw, run_id=None):
    import pandas as pd
    import numpy as np
    import mlflow
    from mlflow.tracking import MlflowClient
    from sklearn.impute import SimpleImputer
    import warnings
    # All imports at the beginning of the function






    # Silence warnings if needed
    warnings.filterwarnings('ignore')

    # Track execution success
    execution_successful = False

    try:
        # Convert data_raw to a Pandas DataFrame if it isn't already
        if not isinstance(data_raw, pd.DataFrame):
            data_raw = pd.DataFrame(data_raw)

        # Create a copy to avoid modifying the original DataFrame
        data = data_raw.copy()

        # 1. Remove the 'Cabin' column
        if 'Cabin' in data.columns:
            data = data.drop(columns=['Cabin'])

        # 2. Impute missing values in 'Age' with the mean
        imputer_age = SimpleImputer(strategy='mean')
        if 'Age' in data.columns:
            data['Age'] = imputer_age.fit_transform(data[['Age']]).ravel()

        # 3. Impute missing values in 'Fare' with the mean
        imputer_fare = SimpleImputer(strategy='mean')
        if 'Fare' in data.columns:
            data['Fare'] = imputer_fare.fit_transform(data[['Fare']]).ravel()

        # 4. Convert specified columns to int64
        for col in ['PassengerId', 'Survived', 'Pclass', 'SibSp', 'Parch']:
            if col in data.columns:
                if data[col].dtype != 'int64':
                    try:
                        data[col] = data[col].astype('int64')
                    except ValueError:
                        print(f"Could not convert column {col} to int64.  Skipping.")

        # 5. Remove duplicate rows
        data = data.drop_duplicates()

        # 6. Remove rows with missing values
        data = data.dropna()

        # If we reach this point without exceptions, execution was successful
        execution_successful = True

        # Store the cleaned data for return
        data_cleaned = data

    except Exception as e:
        print(f"Error during data cleaning: {e}")
        return None

    finally:
        # Only log to MLflow if execution was successful AND run_id is provided
        if execution_successful and run_id is not None:
            # Create MLflow client
            client = MlflowClient()

            # Log data cleaning metrics with function_name prefix
            client.log_param(run_id, "data_cleaner_initial_rows", len(data_raw))
            client.log_param(run_id, "data_cleaner_final_rows", len(data_cleaned))
            client.log_param(run_id, "data_cleaner_removed_rows", len(data_raw) - len(data_cleaned))
            client.log_param(run_id, "data_cleaner_initial_columns", len(data_raw.columns))
            client.log_param(run_id, "data_cleaner_final_columns", len(data_cleaned.columns))

            # Log any dropped columns with function_name prefix
            if len(data_raw.columns) != len(data_cleaned.columns):
                client.log_param(run_id, "data_cleaner_removed_columns", str(list(set(data_raw.columns) - set(data_cleaned.columns))))

        # Return the cleaned data
        return data_cleaned