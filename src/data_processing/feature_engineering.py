# Disclaimer: This function was generated by AI. Please review before using.
# Agent Name: feature_engineering_agent
# Time Created: 2025-03-28 10:06:49

def feature_engineering(data_features, data_target=None, run_id=None):
    import pandas as pd
    import numpy as np
    from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler
    import mlflow
    from mlflow.tracking import MlflowClient
    import warnings
    '''
    Feature engineering function that transforms input features and optionally the target variable.
    
    Parameters:
    ----------
    data_features : pandas.DataFrame
        DataFrame containing the feature columns to be engineered
    data_target : pandas.Series or pandas.DataFrame, optional
        Target variable(s) to be processed alongside features
    run_id : str, optional
        MLflow run ID to use for logging metrics and parameters
        
    Returns:
    -------
    pandas.DataFrame
        DataFrame with engineered features and target column named "target".
        ALL columns will be numerical.
    '''






    # Silence warnings
    warnings.filterwarnings('ignore')
    
    # Track execution success
    execution_successful = False
    
    try:
        # Make a copy of the input data to avoid modifying the original
        data_features = data_features.copy()
        
        # 1. Remove Irrelevant Columns
        data_features = data_features.drop(columns=['PassengerId', 'Name', 'Ticket'], errors='ignore')
        
        # 2. Convert Categorical Features to Numerical
        # One-Hot Encode Sex
        sex_encoded = pd.get_dummies(data_features['Sex'], prefix='Sex')
        sex_encoded = sex_encoded.astype(int)
        data_features = pd.concat([data_features, sex_encoded], axis=1)
        data_features = data_features.drop(columns=['Sex'], errors='ignore')
        
        # One-Hot Encode Embarked
        embarked_encoded = pd.get_dummies(data_features['Embarked'], prefix='Embarked')
        embarked_encoded = embarked_encoded.astype(int)
        data_features = pd.concat([data_features, embarked_encoded], axis=1)
        data_features = data_features.drop(columns=['Embarked'], errors='ignore')
        
        # Create the output dataframe with engineered features
        data_engineered = data_features.copy()
        
        # ALWAYS check and convert any boolean columns to integers (1/0):
        for col in data_engineered.select_dtypes(include=['bool']):
            data_engineered[col] = data_engineered[col].astype(int)
        
        # IMPORTANT: Add the target variable to the final dataframe in a column named "target"
        if data_target is not None:
            # Add target to the engineered features dataframe as a column named exactly "target"
            data_engineered['target'] = data_target
        
        # Final check for any remaining boolean columns
        for col in data_engineered.select_dtypes(include=['bool']):
            data_engineered[col] = data_engineered[col].astype(int)
        
        # If we reach this point without errors, mark execution as successful
        execution_successful = True
        
    except Exception as e:
        print(f"Error during feature engineering: {e}")
        return None
    
    finally:
        # Only log to MLflow if execution was successful AND run_id is provided
        if execution_successful and run_id is not None:
            # Create MLflow client
            client = MlflowClient()
            
            # Log feature engineering metrics with function_name prefix
            client.log_param(run_id, f"feature_engineering_initial_feature_count", len(data_features.columns))
            client.log_param(run_id, f"feature_engineering_engineered_feature_count", len(data_engineered.columns))
            client.log_param(run_id, f"feature_engineering_feature_names", str(list(data_engineered.columns)))
            
            # Log any new features created with function_name prefix
            if len(data_engineered.columns) > len(data_features.columns):
                new_features = set(data_engineered.columns) - set(data_features.columns) - set(['target'])
                if new_features:
                    client.log_param(run_id, f"feature_engineering_new_features", str(list(new_features)))
            
            # If target is provided, log correlations with function_name prefix
            if data_target is not None and 'target' in data_engineered.columns:
                # Log top correlations with target
                try:
                    numeric_cols = data_engineered.select_dtypes(include=['number']).columns
                    correlations = {}
                    for col in numeric_cols:
                        if col != 'target':
                            corr = data_engineered[col].corr(data_engineered['target'])
                            if not pd.isna(corr):
                                correlations[col] = abs(corr)
                                client.log_metric(run_id, f"feature_engineering_corr_{col}", corr)
                    
                    # Log top 5 correlating features with function_name prefix
                    top_features = sorted(correlations.items(), key=lambda x: x[1], reverse=True)[:5]
                    client.log_param(run_id, f"feature_engineering_top_correlating_features", str([f[0] for f in top_features]))
                except Exception as corr_error:
                    print(f"Error calculating correlations: {corr_error}")
        
        # Return the engineered dataframe
        return data_engineered